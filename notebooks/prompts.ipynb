{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2446ba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anthropic import AsyncAnthropic\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import date\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8748e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a data extraction assistant for an AI Model Catalogue database.\n",
    "\n",
    "Your task is to extract information about AI models from unstructured text sources like:\n",
    "- Research papers\n",
    "- Technical blog posts\n",
    "- News articles\n",
    "- Benchmark reports\n",
    "\n",
    "Important guidelines:\n",
    "- Only extract information explicitly stated in the text\n",
    "- Use null for missing fields rather than guessing\n",
    "- Normalize model names to lowercase with hyphens (gpt-4, not GPT4)\n",
    "- Infer release_date from context clues (\"in March 2023\" â†’ \"2023-03-01\")\n",
    "- Keep descriptions concise (1-2 sentences)\n",
    "- Extract metadata as a JSON object when additional details are mentioned\n",
    "\n",
    "Now extract model information from the text provided by the user. If no valid model information can be extracted, return null for all fields.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb8fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractedModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for AI model data extracted by LLM.\n",
    "\n",
    "    Matches ModelCreate but all fields are optional since\n",
    "    extraction may not find complete information.\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str = Field(\n",
    "        ...,\n",
    "        description=\"Technical model identifier\",\n",
    "        examples=[\"gpt-4\", \"claude-3-sonnet\", \"llama-2\"],\n",
    "    )\n",
    "    organization: str | None = Field(\n",
    "        None,\n",
    "        description=\"Organization that created the model\",\n",
    "        examples=[\"OpenAI\", \"Anthropic\", \"Meta\"],\n",
    "    )\n",
    "    release_date: date | None = Field(\n",
    "        None, description=\"Release date in ISO format (YYYY-MM-DD)\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        ..., description=\"Brief description of model capabilities\"\n",
    "    )\n",
    "    license: str | None = Field(\n",
    "        None,\n",
    "        description=\"License type\",\n",
    "        examples=[\"Apache 2.0\", \"MIT\", \"Proprietary\", \"Other\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9fa3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "OpenAI announced GPT-4 on March 14, 2023. GPT-4 is a large multimodal\n",
    "model that can accept image and text inputs and produce text outputs.\n",
    "It exhibits human-level performance on various professional and academic\n",
    "benchmarks. GPT-4 is available via API with a proprietary license.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe787dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedBetaMessage[TypeVar](id='msg_01WzWkTL3U8XFGN4eFWdaVgo', container=None, content=[ParsedBetaTextBlock[TypeVar](citations=None, text='{\"model_name\":\"gpt-4\",\"organization\":\"OpenAI\",\"release_date\":\"2023-03-14\",\"description\":\"A large multimodal model that accepts image and text inputs and produces text outputs, exhibiting human-level performance on various professional and academic benchmarks.\",\"license\":\"Proprietary\"}', type='text', parsed_output=ExtractedModel(model_name='gpt-4', organization='OpenAI', release_date=datetime.date(2023, 3, 14), description='A large multimodal model that accepts image and text inputs and produces text outputs, exhibiting human-level performance on various professional and academic benchmarks.', license='Proprietary'))], context_management=None, model='claude-sonnet-4-5-20250929', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=BetaUsage(cache_creation=BetaCacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=841, output_tokens=70, server_tool_use=None, service_tier='standard'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = AsyncAnthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "system_blocks = [\n",
    "    {\n",
    "        \"type\": \"text\",\n",
    "        \"text\": SYSTEM_PROMPT,\n",
    "        # Add ephemeral cache control if use_cache is True\n",
    "        **({\"cache_control\": {\"type\": \"ephemeral\"}}),\n",
    "    }\n",
    "]\n",
    "\n",
    "response = await client.beta.messages.parse(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    max_tokens=4096,\n",
    "    betas=[\"structured-outputs-2025-11-13\"],\n",
    "    system=system_blocks,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Extract model information from this text:\\n\\n{text}\",\n",
    "        }\n",
    "    ],\n",
    "    output_format=ExtractedModel\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8842b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: gpt-4\n",
      "Organization: OpenAI\n",
      "Release Date: 2023-03-14\n",
      "Description: A large multimodal model that accepts image and text inputs and produces text outputs, exhibiting human-level performance on various professional and academic benchmarks.\n",
      "License: Proprietary\n"
     ]
    }
   ],
   "source": [
    "extracted_model = response.content[0].parsed_output\n",
    "print(\"Model ID:\", extracted_model.model_name)\n",
    "print(\"Organization:\", extracted_model.organization)\n",
    "print(\"Release Date:\", extracted_model.release_date)\n",
    "print(\"Description:\", extracted_model.description)\n",
    "print(\"License:\", extracted_model.license)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3433b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 841\n",
      "Completion tokens: 78\n",
      "Cache read input tokens: 0\n",
      "Cache creation input tokens: 0\n"
     ]
    }
   ],
   "source": [
    "usage = response.usage\n",
    "print(\"Prompt tokens:\", usage.input_tokens)\n",
    "print(\"Completion tokens:\", usage.output_tokens)\n",
    "print(\"Cache read input tokens:\", usage.cache_read_input_tokens)\n",
    "print(\"Cache creation input tokens:\", usage.cache_creation_input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9841834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
